{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and train a GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running locally\n",
    "# !git clone https://github.com/saurabhsharma1993/mac.git\n",
    "# import sys\n",
    "# sys.path.append('./mac')\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from dataset import Dataset, Synth_Dataset, hyperparams\n",
    "from models import *\n",
    "from utils import *\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=15, help='Random seed.')\n",
    "parser.add_argument('--dataset', type=str, default='polblogs', choices=['polblogs','SBM','cora_2comm', 'citeseer_2comm', 'CoauthorCS'], help='dataset')\n",
    "parser.add_argument('--model', type=str, default='sage', choices=['gcn', 'sage'], help='dataset')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--switch_k', type=int, default=2, help='Number of attr perts to make at converted target.')\n",
    "parser.add_argument('--perc_atkrs', type=int, default=100, help='Percentage of maxm attackers.')\n",
    "parser.add_argument('--influence_thresh', type=float, default=2.7, help='Influence cutoff to make attr perts at converted target.')\n",
    "parser.add_argument('--log_dir', type=str, default='', help='Weight of corruption objective.')\n",
    "parser.add_argument('--exp', type=str, default='default', help='name of the experiment.')\n",
    "parser.add_argument('--no_adj_pert', default=False, action='store_true')\n",
    "parser.add_argument('--no_feats_pert', default=False, action='store_true')\n",
    "parser.add_argument('--no_infls_pert', default=False, action='store_true')\n",
    "parser.add_argument('--fixed_ip', default=False, action='store_true')\n",
    "parser.add_argument('--demand', type=int, default=150, help='Number to convert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")\n",
    "args.pert_adj, args.pert_feats = not args.no_adj_pert, not args.no_feats_pert\n",
    "args.infls_pert = not args.no_infls_pert or args.fixed_ip\n",
    "args.cuda = torch.cuda.is_available()\n",
    "\n",
    "root_dir = './logs'\n",
    "log_dir = os.path.join(root_dir,'{}'.format(args.dataset))\n",
    "log_file = os.path.join(log_dir, \"{}.txt\".format(args.exp))\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "device = torch.device(\"cuda:{}\".format(args.device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "hyperparams = hyperparams[args.dataset][args.model]\n",
    "args.influence_thresh, args.switch_k = hyperparams['influence_thresh'], hyperparams['switch_k']\n",
    "\n",
    "for arg in vars(args):\n",
    "    print_write('{}: {}'.format(arg, getattr(args, arg)),log_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset in ['SBM','cora_2comm','citeseer_2comm','CoauthorCS']:\n",
    "    data = Synth_Dataset(name=args.dataset)\n",
    "else:\n",
    "    data = Dataset(root='/tmp/', name=args.dataset)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = adj.shape[0]\n",
    "num_feats = features.shape[1]\n",
    "print_write(\"Num of nodes: {}, num of feats: {}\".format(num_nodes,num_feats),log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset not in ['SBM','cora_2comm','citeseer_2comm','CoauthorCS']:\n",
    "    features, adj, labels = torch.from_numpy(features.todense()), torch.from_numpy(adj.todense()), torch.from_numpy(labels).long()\n",
    "else:\n",
    "    features, adj, labels = torch.from_numpy(features).float(), torch.from_numpy(adj).float(), torch.from_numpy(labels).long()\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "labels = labels.to(device)\n",
    "degrees = torch.sum(adj,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_unlabeled = np.union1d(idx_val, idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'gcn':\n",
    "    model = Trainable_GCN(features.shape[1],16,labels.max().item()+1)\n",
    "else:\n",
    "    model = Trainable_GCN(features.shape[1],16,labels.max().item()+1,use_sage=True)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(features,adj)\n",
    "pred_labels = out.argmax(dim=1)\n",
    "test_acc = (pred_labels[idx_test] == labels[idx_test]).sum() / len(idx_test)\n",
    "print_write(\"Test acc: {:.4f}\".format(test_acc.item()),log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_nodes(target_gcn=None,community='attack',num=10):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = target_gcn.predict(features,adj)\n",
    "        if community == 'attack':\n",
    "            margin_dict = {}\n",
    "            for idx in idx_train:\n",
    "                margin = classification_margin(output[idx], labels[idx])\n",
    "                if margin < 0 or labels[idx] == 1: \n",
    "                    continue\n",
    "                margin_dict[idx] = margin\n",
    "            sorted_margins = sorted(margin_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "            attack_nodes = [x for x, y in sorted_margins]\n",
    "            return attack_nodes, sorted_margins\n",
    "        else:\n",
    "            margin_dict = {}\n",
    "            for idx in idx_test:\n",
    "                margin = classification_margin(output[idx], labels[idx])\n",
    "                pred = output[idx].argmax()\n",
    "                if pred == 0:     # keep all nodes \"classified\" as targets by the ML model\n",
    "                    continue \n",
    "                margin_dict[idx] = margin\n",
    "            sorted_margins = sorted(margin_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "            target_nodes = [x for x,y in sorted_margins]\n",
    "            return target_nodes, sorted_margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select attack and target nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_nodes, attack_node_margins = select_nodes(model,'attack')\n",
    "if args.perc_atkrs != 100:\n",
    "    tot_num = len(attack_nodes)\n",
    "    sel_num = (args.perc_atkrs*tot_num)//100\n",
    "    attack_nodes, attack_node_margins = attack_nodes[:sel_num], attack_node_margins[:sel_num]\n",
    "    print_write('Size of attacking set is now: {}'.format(len(attack_nodes)),log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_nodes, target_node_margins = select_nodes(model,'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_test(adj, features, target_node, source_nodes, gcn=None):\n",
    "    with torch.no_grad():\n",
    "        output = gcn.predict(features, adj)\n",
    "        probs = torch.softmax(output[target_node],dim=0)\n",
    "        margin = classification_margin(output[target_node],labels[target_node])\n",
    "        preds = output.argmax(1)\n",
    "        pred = preds[target_node]\n",
    "        backflips = (preds[source_nodes] == 1).sum()\n",
    "        acc_test = (pred == pred_labels[target_node]) if (pred_labels[target_node] == 1)\\\n",
    "                   else (pred != pred_labels[target_node]) \n",
    "        return acc_test.item(), backflips, pred, margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_perts(pert_inds_comb,n_perturbations,num_nodes,num_feats,pert_adj=True,pert_feats=True):\n",
    "    if pert_adj and pert_feats:\n",
    "        comb_grad_argmax = pert_inds_comb[:,-n_perturbations:]\n",
    "        grad_argmax_adj, grad_argmax_feats = comb_grad_argmax[:,comb_grad_argmax[1,:] < num_nodes], \\\n",
    "                                             comb_grad_argmax[:,comb_grad_argmax[1,:] >= num_nodes]\n",
    "        grad_argmax_feats[1,:] = grad_argmax_feats[1,:] - num_nodes \n",
    "    elif pert_adj and not pert_feats:\n",
    "        pert_inds_adj = pert_inds_comb[:,pert_inds_comb[1,:] < num_nodes]\n",
    "        grad_argmax_adj, grad_argmax_feats = pert_inds_adj[:,-n_perturbations:], None\n",
    "    elif not pert_adj and pert_feats:\n",
    "        pert_inds_feats = pert_inds_comb[:,pert_inds_comb[1,:] >= num_nodes]\n",
    "        grad_argmax_adj, grad_argmax_feats = None, pert_inds_feats[:,-n_perturbations:]\n",
    "        grad_argmax_feats[1,:] = grad_argmax_feats[1,:] - num_nodes \n",
    "    else:\n",
    "        raise Exception('Must pert at least one of edges and feats.')\n",
    "    return grad_argmax_adj, grad_argmax_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_single_target(target_node,source_nodes,budget=1,pert_inds_comb=None,pert_adj=True,pert_feats=True):\n",
    "    n_perturbations = int(budget)                 \n",
    "    assert n_perturbations > 0, 'Number of perturbations is 0!'\n",
    "    num_nodes = adj.shape[0]\n",
    "    num_feats = features.shape[1]\n",
    "    \n",
    "    # to gather gradients on adj\n",
    "    modified_adj = adj.detach().clone()\n",
    "    modified_adj.requires_grad = True\n",
    "    \n",
    "    # to gather gradients on features\n",
    "    modified_features = features.detach().clone()\n",
    "    modified_features.requires_grad = True\n",
    "    \n",
    "    # reuse pert_inds from previous iter if available\n",
    "    if pert_inds_comb is None:\n",
    "        \n",
    "        modified_adj.requires_grad = True\n",
    "        out = model.predict(modified_features,modified_adj)\n",
    "        loss = F.cross_entropy(out[[target_node]], pred_labels[[target_node]])    \n",
    "        \n",
    "        grad_adj, grad_feats = torch.autograd.grad(loss, [modified_adj, modified_features])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            grad_adj = (grad_adj + grad_adj.T) * (-modified_adj + 1)            # deletions get zeroed out\n",
    "            grad_adj[target_node,target_node] = -10                                               # self loops disallowed\n",
    "            \n",
    "            fudge = 2*torch.max(torch.max(torch.abs(grad_adj)),torch.max(torch.abs(grad_feats)))\n",
    "            grad_adj[source_nodes,:] = grad_adj[source_nodes,:] + fudge    # edge perts from source nodes have highest gradient\n",
    "            grad_feats[source_nodes,:] = grad_feats[source_nodes,:] + fudge    # attribute perts from source nodes have highest gradient\n",
    "            comb_grad = torch.cat((grad_adj,grad_feats),dim=1)\n",
    "            grad_sort_comb, pert_inds_comb = torch.sort(comb_grad.flatten())         \n",
    "            pert_inds_comb = torch.stack([pert_inds_comb//(num_nodes+num_feats), pert_inds_comb%(num_nodes+num_feats)]).long()\n",
    "            \n",
    "            # filter out non-positive gradients, such as deletions and useless insertions\n",
    "            nnp_inds_comb = grad_sort_comb <= 0\n",
    "            pert_inds_comb = pert_inds_comb[:,~nnp_inds_comb]\n",
    "            \n",
    "            # only check lower triangular indices of adj\n",
    "            select = torch.logical_or(pert_inds_comb[0,:] < pert_inds_comb[1,:], pert_inds_comb[1,:] >= num_nodes)       \n",
    "            pert_inds_comb = pert_inds_comb[:,select]\n",
    "        \n",
    "    grad_argmax, grad_feats_argmax = pick_perts(pert_inds_comb,n_perturbations,num_nodes,num_feats,pert_adj=pert_adj,pert_feats=pert_feats)\n",
    "            \n",
    "    # make updates\n",
    "    if pert_adj:\n",
    "        value = -modified_adj[grad_argmax[0],grad_argmax[1]] + 1       \n",
    "        modified_adj.data[grad_argmax[0],grad_argmax[1]] += value\n",
    "        modified_adj.data[grad_argmax[1],grad_argmax[0]] += value\n",
    "    \n",
    "    if pert_feats:\n",
    "        value = -2*modified_features[grad_feats_argmax[0],grad_feats_argmax[1]] + 1       \n",
    "        modified_features.data[grad_feats_argmax[0],grad_feats_argmax[1]] += value\n",
    "    \n",
    "    acc, backflips, pred, margin = single_test(modified_adj, modified_features, target_node, source_nodes, gcn=model)\n",
    "    \n",
    "    return acc, pred, margin, grad_argmax, grad_feats_argmax, pert_inds_comb, modified_adj, modified_features, backflips\n",
    "    \n",
    "## bisection method to compute budget    \n",
    "def bin_search_fga(target_node, source_nodes, pert_inds_comb = None, pert_adj = True, pert_feats = True):\n",
    "    l_budget, u_budget = 0, degrees[target_node].item()\n",
    "    l_acc, backflips, _, _ = single_test(adj, features, target_node, source_nodes, gcn=model)\n",
    "    if l_acc == 0:\n",
    "        modified_adj, modified_features = adj.detach().clone(), features.detach().clone()\n",
    "        modified_adj.requires_grad, modified_features.requires_grad = True, True        \n",
    "        return l_budget, None, None, modified_adj, modified_features, backflips\n",
    "    u_acc = 1\n",
    "    max_budget = torch.max(degrees)   \n",
    "    # find upper bound on required budget.\n",
    "    while u_acc == 1:\n",
    "        if u_budget > max_budget.item():\n",
    "            return math.inf, None, None, None, None, None    \n",
    "        u_acc, _, _, grad_argmax, grad_feats_argmax, pert_inds_comb, modified_adj, modified_features, backflips = attack_single_target(target_node,source_nodes,u_budget,pert_inds_comb,pert_adj,pert_feats)\n",
    "        if u_acc == 1:\n",
    "            u_budget = 2*u_budget\n",
    "    while u_budget - l_budget > 1:    \n",
    "        c_budget = (l_budget + u_budget) // 2\n",
    "        c_acc, _, _, grad_argmax, grad_feats_argmax, pert_inds_comb, modified_adj, modified_features, backflips = attack_single_target(target_node,source_nodes,c_budget,pert_inds_comb,pert_adj,pert_feats)\n",
    "        if c_acc == 1:\n",
    "            l_budget = c_budget\n",
    "        else:\n",
    "            u_budget = c_budget\n",
    "    u_acc, _, _, grad_argmax, grad_feats_argmax, pert_inds_comb, modified_adj, modified_features, backflips = attack_single_target(target_node,source_nodes,u_budget,pert_inds_comb,pert_adj,pert_feats)\n",
    "    del(pert_inds_comb)\n",
    "    return u_budget, grad_argmax, grad_feats_argmax, modified_adj, modified_features, backflips         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_influence_lookahead(target_node, target_set, modified_adj, modified_features, switch_k = 2):\n",
    "    \n",
    "    out = model.predict(modified_features,modified_adj)  \n",
    "    obj = torch.sum(out[target_set,0] - out[target_set,1]) \n",
    "    # get gradient on target attributes\n",
    "    grad_feats = torch.autograd.grad(obj, modified_features)[0][target_node,:]                                          \n",
    "    grad_feats = grad_feats * (-2*modified_features[target_node,:] + 1)\n",
    "    grad_feats_sort, sort_inds = torch.sort(grad_feats)\n",
    "    \n",
    "    # filter nnp gradient\n",
    "    nnp_inds = grad_feats_sort <= 0\n",
    "    grad_feats_sort, sort_inds = grad_feats_sort[~nnp_inds], sort_inds[~nnp_inds]  \n",
    "    \n",
    "    # make top-k attr perts of target node\n",
    "    grad_feats_argmax = sort_inds[-switch_k:]\n",
    "    value = -2 * modified_features[target_node, grad_feats_argmax] + 1       \n",
    "    pert_features = modified_features.detach().clone()\n",
    "    pert_features[target_node, grad_feats_argmax] += value\n",
    "    \n",
    "    # now gradient of 2nd order perts on edges\n",
    "    out_lookahead = model.predict(pert_features,modified_adj)\n",
    "    obj = torch.sum(out_lookahead[target_set,0] - out_lookahead[target_set,1]) \n",
    "    \n",
    "    grad_adj = torch.autograd.grad(obj, modified_adj)[0]\n",
    "    grad_adj[target_node,target_node] = -10                          # no self loops\n",
    "    grad_adj = (grad_adj + grad_adj.T)[target_node,:]\n",
    "    grad_adj = grad_adj * (-modified_adj[target_node,:] + 1)         # considering insertions only\n",
    "    grad_adj = grad_adj[target_set]\n",
    "    \n",
    "    # filter nnp gradient\n",
    "    nnp_inds = grad_adj <= 0\n",
    "    grad_adj = grad_adj[~nnp_inds]\n",
    "    \n",
    "    # sum all 2nd order nnn gradients\n",
    "    influence = torch.sum(grad_adj).item() / len(target_set)\n",
    "        \n",
    "    return influence, grad_feats_argmax, pert_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find min budget target with highest influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(target_nodes, source_nodes, switch_k = 2):\n",
    "    \n",
    "    best_budget, best_influence, best_target_perts = 1e13, 0, None\n",
    "    best_target_node, best_grad_argmax, best_grad_feats_argmax = None, None, None\n",
    "    best_modified_adj, best_modified_features, best_pert_features = None, None, None\n",
    "    best_backflips = 1e13\n",
    "    for ind, target_node in enumerate(target_nodes):\n",
    "        budget, grad_argmax, grad_feats_argmax, modified_adj, modified_features, backflips = bin_search_fga(target_node,source_nodes,None,args.pert_adj,args.pert_feats)\n",
    "        if budget == math.inf or budget > best_budget:\n",
    "            continue\n",
    "        \n",
    "        target_set = deepcopy(target_nodes)\n",
    "        target_set.remove(target_node) \n",
    "        \n",
    "        if args.infls_pert: \n",
    "            influence, target_perts, pert_features = target_influence_lookahead(target_node, target_set, modified_adj, modified_features, switch_k)\n",
    "        else:\n",
    "            influence, target_perts, pert_features = 0, None, None\n",
    "        if budget < best_budget or (budget == best_budget and influence > best_influence and backflips <= best_backflips):\n",
    "        \n",
    "            best_budget = budget\n",
    "            best_target_node, best_grad_argmax, best_grad_feats_argmax = target_node, grad_argmax, grad_feats_argmax\n",
    "            best_influence, best_target_perts = influence, target_perts\n",
    "            best_modified_adj = modified_adj\n",
    "            # make attribute perts at converted target node if its influence is good. or if using fixed ip\n",
    "            best_modified_features = pert_features if args.infls_pert and ((influence != 0 and influence >= args.influence_thresh) or args.fixed_ip) else modified_features\n",
    "            best_backflips = backflips\n",
    "    return best_target_node, best_budget, best_grad_argmax, best_grad_feats_argmax, best_influence, best_target_perts, best_modified_adj, best_modified_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert selected target and make perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_attack_step(target_nodes,source_nodes,switch_k=2,pert_adj=True,pert_feats=True):\n",
    "    \n",
    "    # score and pick node to flip and corrupt\n",
    "    target_node, budget, grad_argmax, grad_feats_argmax, influence, target_perts, modified_adj, modified_features = score(target_nodes, source_nodes, switch_k)\n",
    "    \n",
    "    # check if any target node is flippable at all\n",
    "    if budget == math.inf or budget == 1e13:\n",
    "        return target_nodes, source_nodes, None, None, None, None, None, None\n",
    "    elif budget > 0:\n",
    "        # make updates\n",
    "        global adj \n",
    "        adj = modified_adj.detach().clone()\n",
    "        global features\n",
    "        features = modified_features.detach().clone()\n",
    "    else: \n",
    "        pass\n",
    "    all_ips = {}\n",
    "    # print attribute perts at converted target node if its influence is good\n",
    "    if args.infls_pert and ((influence != 0 and influence >= args.influence_thresh) or args.fixed_ip):\n",
    "        print_write('Influence is good at node: {}'.format(target_node),log_file)\n",
    "        print_write('Influential perturbations at node {}.'.format(target_node),log_file)\n",
    "        print_write(target_perts.data.cpu().numpy(),log_file)\n",
    "        budget = budget + switch_k # add perts at converted target to budget\n",
    "        all_ips[target_node] = target_perts\n",
    "    \n",
    "    print_write(\"Target node: {}, Budget: {}\".format(target_node,budget),log_file)\n",
    "    print_write(\"Edge perturbations.\",log_file)\n",
    "    print_write(grad_argmax.data.cpu().numpy(),log_file)\n",
    "    print_write(\"Feature perturbations.\",log_file)\n",
    "    print_write(grad_feats_argmax.data.cpu().numpy(),log_file)\n",
    "\n",
    "    # recompute set of attacking and target nodes. comment out for baseline or ablations.\n",
    "    new_target_nodes, _ = select_nodes(model,'target')\n",
    "    converted_nodes = list(set.difference(set(target_nodes),set(new_target_nodes)))\n",
    "    print_write(\"Converted nodes.\",log_file)\n",
    "    print_write(converted_nodes,log_file)\n",
    " \n",
    "    converted_nodes.remove(target_node)\n",
    "    converted_nodes = [target_node] + converted_nodes # for tracking purpose, keep target at index 0.\n",
    "    target_nodes = new_target_nodes\n",
    "    source_nodes = source_nodes + converted_nodes\n",
    "    \n",
    "    backflips = list(set.intersection(set(target_nodes),set(source_nodes)))\n",
    "    for node in backflips:\n",
    "        print_write('Node {} backflipped.'.format(node),log_file)\n",
    "        source_nodes.remove(node)\n",
    "    return target_nodes, source_nodes, converted_nodes, budget, influence, all_ips, grad_argmax, grad_feats_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(rand_cuda_var):\n",
    "    if rand_cuda_var == None:\n",
    "        return rand_cuda_var\n",
    "    else:\n",
    "        return rand_cuda_var.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run multi-step attack and output sequence of attack edges, budgets, perturbations, and converted target nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    num_nodes = adj.shape[0]\n",
    "    converted_nodes, budgets, influences, attack_edges, attribute_switches, infl_perts, num_converted = [], [], [], [], [], [], []\n",
    "    other_target_nodes = (labels[idx_train] == 1).sum() + (labels[idx_val] == 1).sum()\n",
    "    start_time = time()\n",
    "    init_target_size = len(target_nodes)\n",
    "    last_best, time_since = init_target_size, 0\n",
    "    while True:\n",
    "        sys.stdout.flush()\n",
    "        target_nodes, attack_nodes, converted_node_list, budget, influence, all_ips, grad_argmax, grad_feats_argmax = local_attack_step(target_nodes, attack_nodes, args.switch_k, args.pert_adj, args.pert_feats)\n",
    "        if converted_node_list == None:\n",
    "            print_write('Attack failed. No target node is flippable.',log_file)\n",
    "            break\n",
    "        converted_nodes.append(converted_node_list) \n",
    "        budgets.append(budget)                                                                 \n",
    "        influences.append(influence)\n",
    "        attack_edges.append(to_numpy(grad_argmax))\n",
    "        attribute_switches.append(to_numpy(grad_feats_argmax))\n",
    "        infl_perts.extend([(k,to_numpy(v)) for (k,v) in all_ips.items()])\n",
    "        num_converted.append(init_target_size - len(target_nodes))\n",
    "        \n",
    "        # if target set size doesn't improve for 40 steps, stop.\n",
    "        if len(target_nodes) < last_best:\n",
    "            last_best, time_since = len(target_nodes), 0\n",
    "        else:\n",
    "            time_since += 1\n",
    "        if time_since >= 40:\n",
    "            print_write('Failure. Attack didn\\'t decrease target size for 40 steps.',log_file)\n",
    "            break\n",
    "        end_time = time()\n",
    "        runtime = end_time - start_time\n",
    "        print_write(\"Time taken for {} steps: {:.2f} secs. Estimated total: {:.2f} secs.\".format(len(budgets),runtime,runtime*(args.demand)/len(budgets)),log_file)\n",
    "        \n",
    "        if init_target_size - len(target_nodes) >= args.demand: # stopping criterion\n",
    "            break\n",
    "    end_time = time()\n",
    "    runtime = end_time - start_time\n",
    "    total_budget = sum(budgets)\n",
    "    \n",
    "    print_write(\"Time taken to attack: {:.2f} seconds\".format(runtime),log_file)\n",
    "    print_write(\"Total budget: {}\".format(total_budget),log_file)\n",
    "    \n",
    "    results = {'args': args,\\\n",
    "                'converted_nodes': converted_nodes,\\\n",
    "    \t\t\t'budgets': budgets,\\\n",
    "                'total_budget': total_budget,\\\n",
    "    \t\t\t'influences': influences,\\\n",
    "    \t\t\t'attack_edges': attack_edges,\\\n",
    "                'runtime': runtime,\\\n",
    "    \t\t\t'attribute_switches': attribute_switches,\\\n",
    "                'infl_perts': infl_perts,\\\n",
    "                'num_converted': num_converted}\n",
    "    with open(os.path.join(log_dir,'{}.pkl'.format(args.exp)), 'wb') as f:\n",
    "    \tpickle.dump(results,f)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
